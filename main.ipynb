{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T16:00:24.706249Z",
     "start_time": "2024-04-04T16:00:17.653650Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.get_device_properties(0).total_memory)\n",
    "\n",
    "# Get number of cores\n",
    "print(os.cpu_count())\n",
    "\n",
    "# Get number of threads\n",
    "print(torch.get_num_threads())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla V100-SXM2-32GB\n",
      "34072559616\n",
      "72\n",
      "36\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from model import RoadModel\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from src import RoadDataModule, LogPredictionsCallback, val_checkpoint, regular_checkpoint\n",
    "\n",
    "\n",
    "def main(cfg: DictConfig) -> None:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = RoadModel(cfg, device)\n",
    "    datamodule = RoadDataModule(cfg)\n",
    "\n",
    "    wandb_logger = WandbLogger(project=\"road-segmentation\", name=\"test\")\n",
    "\n",
    "    trainer = L.Trainer(max_epochs=5, accelerator=\"gpu\", devices=1, logger=wandb_logger, callbacks=[\n",
    "        LogPredictionsCallback(),\n",
    "        val_checkpoint,\n",
    "        regular_checkpoint\n",
    "    ])\n",
    "    # trainer.fit(model, datamodule=datamodule)\n",
    "    trainer.test(model, datamodule=datamodule)\n",
    "    # trainer.predict(model, datamodule=datamodule)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T16:00:33.274582Z",
     "start_time": "2024-04-04T16:00:27.753719Z"
    }
   },
   "id": "59a15fe8a2f1c603",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "with initialize(version_base=None, config_path=\"conf\"):\n",
    "    config = compose(config_name=\"config\")\n",
    "    main(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T13:37:14.587816Z",
     "start_time": "2024-04-04T13:35:28.429124Z"
    }
   },
   "id": "a1e7f9f60038cca3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33maleskucera\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240404_153539-72xne7br</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aleskucera/road-segmentation/runs/72xne7br' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/aleskucera/road-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/aleskucera/road-segmentation' target=\"_blank\">https://wandb.ai/aleskucera/road-segmentation</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/aleskucera/road-segmentation/runs/72xne7br' target=\"_blank\">https://wandb.ai/aleskucera/road-segmentation/runs/72xne7br</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n",
      "/mnt/appl/software/PyTorch/2.0.1-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f549e629065413a914e7b55f6374645"
      },
      "application/json": {
       "n": 0,
       "total": null,
       "elapsed": 0.39121222496032715,
       "ncols": null,
       "nrows": null,
       "prefix": "Testing",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": "{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_noinv_fmt}{postfix}]",
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/appl/software/PyTorch-Lightning/2.1.0-foss-2022a-CUDA-11.7.0/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T13:37:14.597213Z",
     "start_time": "2024-04-04T13:37:14.593131Z"
    }
   },
   "id": "53669759794a124f",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
